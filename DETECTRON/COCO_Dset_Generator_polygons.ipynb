{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are many semantic segmentation tools available, and they all require image annotations in one of several specific formats. In this notebook we will create COCO annotations for the Sartoruis dataset. There are many conversion tools available that can convert from COCO to a different target format as well, so COCO is quite versatile."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.mask import encode, area, toBbox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import glob\n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "import skimage.io as io\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from os.path import exists\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download and preparing Dsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " - [create-coco-annotations-from-scratch](https://www.immersivelimit.com/create-coco-annotations-from-scratch)\n",
    " - [pycocotools](https://github.com/cocodataset/cocoapi/tree/master/PythonAPI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_dir = './sartorius-cell-instance-segmentation'\n",
    "\n",
    "TRAIN_CSV = f\"{data_dir}/train.csv\"\n",
    "TRAIN_PATH = f\"{data_dir}/train\"\n",
    "TEST_PATH = f\"{data_dir}/test\"\n",
    "# annFile_path = f\"{data_dir}/annotations_train.json\"\n",
    "\n",
    "ROOT = Path(data_dir)\n",
    "#TRAIN_FILES = Path(TRAIN_PATH)\n",
    "\n",
    "WIDTH = 704\n",
    "HEIGHT = 520\n",
    "\n",
    "# Normalize to resnet mean and std if True.\n",
    "# RESNET_MEAN = [0.485, 0.456, 0.406]\n",
    "# RESNET_STD = [0.229, 0.224, 0.225]\n",
    "IMAGE_RESIZE = (224, 224)\n",
    "TH = 40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a few lists with files, ids and cell type for later use:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# FILE_NAMES = sorted(list(Path(TRAIN_PATH).rglob('*png')))\n",
    "# cell_type = []\n",
    "# files = []\n",
    "# for file_indx in FILE_NAMES:\n",
    "#     files.append(file_indx.stem)\n",
    "#     cell_type.append(df[df.id == str(file_indx.stem)].cell_type.iloc[0])\n",
    "\n",
    "FILE_NAMES = glob.glob('./sartorius-cell-instance-segmentation/train/*.png')\n",
    "cell_type = []\n",
    "fids = []\n",
    "for i in range(len(FILE_NAMES)):\n",
    "    fid = FILE_NAMES[i].split('/')[-1].split('.')[0]\n",
    "    fids.append(fid)\n",
    "    cell_type.append(df[df.id == fid].cell_type.iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create COCO files\n",
    "\n",
    "Conversion is pretty slow, going from binary masks to polygons."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stratify on cell type and create one COCO .json file for train and test per fold."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "CATEGORIES = {\"shsy5y\": 1, \"astro\":2, \"cort\": 3}\n",
    "# ref: https://www.kaggle.com/inversion/run-length-decoding-quick-start\n",
    "def rle_decode(mask_rle, mask, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height, width, channels) of array to return\n",
    "    color: color for the mask\n",
    "    Returns numpy array (mask)\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "\n",
    "    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n",
    "    lengths = list(map(int, s[1::2]))\n",
    "    ends = [x + y for x, y in zip(starts, lengths)]\n",
    "\n",
    "    img = mask.reshape((mask.shape[0] * mask.shape[1]))\n",
    "\n",
    "    for start, end in zip(starts, ends):\n",
    "        img[start : end] = color\n",
    "\n",
    "    return img.reshape(mask.shape)\n",
    "\n",
    "def create_segmentation(sub_mask):\n",
    "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
    "    segmentations = []\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        if len(contour) > 2:\n",
    "            poly = Polygon(contour)\n",
    "            poly = poly.simplify(1.0, preserve_topology=False)\n",
    "            if not poly.is_empty:\n",
    "                try: # might fail if polygons are not connected\n",
    "                    segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "                    for i in range(len(segmentation)):\n",
    "                        segmentation[i] = np.clip(segmentation[i], 0, 1e6)\n",
    "                    segmentations.append(segmentation)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    return segmentations\n",
    "\n",
    "# https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/291371\n",
    "def fill_hole(m):\n",
    "    filled = m.copy()\n",
    "    pad = np.pad(m, 4)\n",
    "    lb = measure.label(pad < 0.5, background=0, connectivity=1)\n",
    "    u, cc = np.unique(lb, return_counts=True)\n",
    "    if len(u) > 2:\n",
    "        #print(u, cc)\n",
    "        lb = lb[4:-4, 4:-4]\n",
    "        for uu in u[2:]:\n",
    "            filled[lb == uu] = 1\n",
    "\n",
    "    return filled\n",
    "\n",
    "\n",
    "CLEAN_M = './clean-astro-mask/'\n",
    "\n",
    "\n",
    "def create_single_mask(annotation, img_size, r=None):\n",
    "    mask = np.zeros(img_size, dtype=np.uint8)\n",
    "    mask = rle_decode(annotation, mask)\n",
    "    mask = fill_hole(mask)\n",
    "    if r is not None:\n",
    "        mask = mask & r\n",
    "    return mask\n",
    "\n",
    "def add_image(df, fid, fpath, tset, aid, status):\n",
    "    idx = len(tset[\"images\"])+1\n",
    "    h = df[df.id == fid].height.iloc[0]\n",
    "    w = df[df.id == fid].width.iloc[0]\n",
    "    tset['images'].append({\"height\": int(h),\n",
    "                           \"width\": int(w),\n",
    "                           \"id\": int(idx),\n",
    "                           \"file_name\": f'{status}/{fpath.name}'})#.replace('\\\\', '/')})\n",
    "    adf = df[df.id == fid]\n",
    "    # check for cleaned mask\n",
    "    ipath = CLEAN_M+fid+'.png'\n",
    "    if exists(ipath):\n",
    "        corr = plt.imread(ipath)\n",
    "        # extract red channel\n",
    "        r = corr[:,:,0].astype(np.uint8)\n",
    "    else:\n",
    "        r = None\n",
    "    # add each object as segment\n",
    "    for j in range(len(adf)):\n",
    "        cat = CATEGORIES[df[df.id == fid].cell_type.iloc[j]]\n",
    "        # create mask\n",
    "        m = create_single_mask(df[df.id == fid].annotation.iloc[j], [h, w], r)\n",
    "        # encode as RLE\n",
    "        me = encode(np.asfortranarray(m))\n",
    "        # calc stats\n",
    "        bbox = toBbox(me).astype(np.int32).tolist()\n",
    "        a = area(me)\n",
    "        # Polygons\n",
    "        poly = create_segmentation(m)\n",
    "        if len(poly) > 0:\n",
    "            tset[\"annotations\"].append({\"iscrowd\": 0,\n",
    "                                        \"image_id\": int(idx),\n",
    "                                        \"bbox\": bbox,\n",
    "                                        \"segmentation\": poly,\n",
    "                                        \"category_id\": int(cat),\n",
    "                                        \"id\": int(aid),\n",
    "                                        \"area\": int(a)})\n",
    "            aid += 1\n",
    "    return tset, aid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def create_coco(files, idx,status):\n",
    "    # define overall structure\n",
    "    train_set = {\"images\": [], \"categories\": [], \"annotations\": []}\n",
    "    # define classes\n",
    "    train_set[\"categories\"].append({\"supercategory\": \"cells\", \"id\": 1, \"name\": \"shsy5y\"})\n",
    "    train_set[\"categories\"].append({\"supercategory\": \"cells\", \"id\": 2, \"name\": \"astro\"})\n",
    "    train_set[\"categories\"].append({\"supercategory\": \"cells\", \"id\": 3, \"name\": \"cort\"})\n",
    "\n",
    "    anno_id = 1 # start annotation ID at 1\n",
    "    for i in tqdm(range(len(files))):\n",
    "        train_set, anno_id = add_image(df, idx[i], files[i], train_set, anno_id,status)\n",
    "    return train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 484/484 [13:47<00:00,  1.71s/it]\n",
      "100%|██████████| 122/122 [03:49<00:00,  1.88s/it]\n",
      "100%|██████████| 485/485 [14:24<00:00,  1.78s/it]\n",
      "100%|██████████| 121/121 [03:24<00:00,  1.69s/it]\n",
      "100%|██████████| 485/485 [14:11<00:00,  1.76s/it]\n",
      "100%|██████████| 121/121 [03:43<00:00,  1.85s/it]\n",
      "100%|██████████| 485/485 [14:21<00:00,  1.78s/it]\n",
      "100%|██████████| 121/121 [03:30<00:00,  1.74s/it]\n",
      "100%|██████████| 485/485 [14:33<00:00,  1.80s/it]\n",
      "100%|██████████| 121/121 [03:24<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "K_FOLDS = 5\n",
    "\n",
    "kf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=777)\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(FILE_NAMES, cell_type)):\n",
    "    # train set\n",
    "    train_ds = [FILE_NAMES[i] for i in train_index]\n",
    "    train_fids = [fids[i] for i in train_index]\n",
    "    tset = create_coco(train_ds, train_fids)\n",
    "    with open('train_fold_{}.json'.format(fold), 'w') as f:\n",
    "        json.dump(tset, f, indent=4)\n",
    "    # test set\n",
    "    valid_ds = [FILE_NAMES[i] for i in test_index]\n",
    "    valid_fids = [fids[i] for i in test_index]\n",
    "    vset = create_coco(valid_ds, valid_fids)\n",
    "    with open('test_fold_{}.json'.format(fold), 'w') as f:\n",
    "        json.dump(vset, f, indent=4)\n",
    "\n",
    "    del tset, vset\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures in train dir: 606 pcs\n",
      "\n",
      "Number of pictures in test dir: 3 pcs\n"
     ]
    }
   ],
   "source": [
    "train_files = sorted(list(Path(TRAIN_PATH).rglob('*png')))\n",
    "test_files = sorted(list(Path(TEST_PATH).rglob('*.png')))\n",
    "print(f'Number of pictures in train dir: {len(train_files)} pcs')\n",
    "print()\n",
    "print(f'Number of pictures in test dir: {len(test_files)} pcs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# Split dataset to train and val sets\n",
    "train_pics, val_pics = train_test_split(train_files, test_size=0.1,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures in train set: 545\n",
      "\n",
      "Number of pictures in val set: 61\n"
     ]
    }
   ],
   "source": [
    "# Extract pic Id from Path\n",
    "train_pic_id = [path.stem for path in train_pics]\n",
    "val_pic_id = [path.stem for path in val_pics]\n",
    "# Print number of files in tran and val sets\n",
    "print(f'Number of pictures in train set: {len(train_pics)}')\n",
    "print()\n",
    "print(f'Number of pictures in val set: {len(val_pics)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 545/545 [15:57<00:00,  1.76s/it]\n",
      "100%|██████████| 61/61 [01:52<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "train_set = create_coco(train_pics, train_pic_id,'train')\n",
    "val_set = create_coco(val_pics, val_pic_id,'train')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [17:12<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "all_set = create_coco(train_files, [path.stem for path in train_files],'train')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "with open('annotations_train_poly.json', 'w') as f:\n",
    "        json.dump(train_set, f, indent=4)\n",
    "\n",
    "with open('annotations_val_poly.json', 'w') as f:\n",
    "        json.dump(val_set, f, indent=4)\n",
    "\n",
    "# with open('annotations_all_poly.json', 'w') as f:\n",
    "#         json.dump(all_set, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}